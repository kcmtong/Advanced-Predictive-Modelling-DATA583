---
title: "Data 583 Life Expectancy (WHO)"
author: "Justin Chan, Kenny Tong, Viji Rajagopalan"
date: "22 Mar, 2023"
output:
  pdf_document: default
  html_document:
    df_print: paged
fontsize: 10pt
geometry: margin=2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data 583 Life Expectancy - Final Report (Life Expectancy Data)

## Part 1. Introduction and Hypotheses
Life Expectancy has always been an area of interest for humanity.  The dataset contains the Life Expectancy records of 193 countries between 2000-2015, together with different predictive factors. Broadly speaking, predicting variables are categorized into 4 major areas : Immmunization, Mortality, Economical, and Social, containing a total of 21 individual variables.

The primary purpose of this report is to compare and evaluate different predictive models in order to identify the most appropriate model for the dataset.  In particular, we will evaluate the applicability of the core assumptions of the selected models by methods such as Normality Test, Multicollinearity Assessment, etc. This could validate or decline the adoption of certain models because the model assumptions are simply not satisfied.  We are also going to verify whether the 4 predicting areas have equal significance on Life Expectancy, and whether there are adequate support evidence suggesting a strong correlation with the response variables.  Finally, we will also perform and compare fitting result of selected models, in particular whether parametric models would be more suitable than non-parametric models for this dataset. 

## Part 2. Dataset overview

### Varaibles Types
|Variable     |Unit of Measurement/Data Category    | Continuous vs Discrete |   Variable     |Unit of Measurement/Data Category    | Continuous vs Discrete |
|-----        |-----                                | ----- |   -----        |-----                                | ----- |
|Life Expectancy |Years Old (Age)                   |Continuous  |Total expenditure|Percentage                       |Continuous|
|Country      |Nominal Data                         |Discrete  |Percentage expenditure|Percentage                  |Continuous|
|Year         |Ordinal Data                         |Discrete  |GDP          |Currency (USD)                       |Continuous|
|Status       |Nominal Data                         |Discrete  |Population   |Count                                |Discrete|
|Adult Mortality|Count Data                         |Discrete  |Income composition of resources|Percentage         |Continuous|
|Infant deaths|Count Data                           |Discrete  |Schooling    |Mean (Years)                         |Continuous|
|Under-five deaths|Count Data                       |Discrete  |Alcohol      |Litres                               |Continuous|
|Hepatitis B  |Percentage                           |Continuous  |HIV/AIDS     |Percentage                           |Continuous|
|Measles      |Count Data                           |Discrete  |BMI          |Average BMI                          |Continuous|
|Polio        |Percentage                           |Continuous  |Thinness 1-19 years|Percentage                     |Continuous|
|Diphtheria   |Percentage                           |Continuous  |Thinness 5-9 years|Percentage                      |Continuous|



### Variables Summary and Categories
Life Expectancy is the response variable in this dataset.  This represents the mean of the life expectancy (in age) in a specific country in a given year.  For the data types of the predicting variables, most are percentage and count data across four major areas.  The first area is Immunization Data such as Hepatitis B and Polio (immunization coverage).  The second area is Mortality Data such as Adult Mortality/infant deaths (No. of deaths of Adult/infant per 1000 persons).  The third area is Economical Data such as GDP/Income composition/Percentage expenditure.  The fourth area is Social Data such as Schooling and Population.
 
To clean up and wrangle data for the subsequent analysis, NA data has been assessed.  A total of 2563 NA values are found in the dataset, spreading across a few columns.  These NA values are generally imputed by the respective column mean.   

### Checking for Multicollinearity
As Multicollinearity can potentially affect the accuracy of regression model and we have 22 variables, a correlation study is undertaken to understand and assess the situation.  A correlation plot has identified a number of correlation problems.  It is found that infant deaths and under.five.deaths are nearly 100% correlated.  The relation between the deaths rates of the two close age groups is easily interpretable.  In addition, there are three heavily correlated pairs which is defined by the abs(correlation coefficient)>0.7 between the variables.  They include (a) (immunization rate of) ‘Polio’-vs-‘Diphtheria’,  (b) ‘income composition of resources’-vs-‘Schooling’, and (c) between the two thinness measures for the age groups 5-9 vs 10-19.   Pairs (a) and (c) are justifiable while the relation for (b) demonstrate a relatively subtle relation.  Other than that, the degree of multicollinearity is acceptable and not too worrying.



```{r, include=FALSE}
### Start of EDA section - retained in Rmd

le <- read.csv("dataset/LifeExpectancy.csv")

# Create a new column Status.val to represent the Status column with number
le$Status.val <- ifelse(le$Status == "Developed",1,0)
# Create a new column as the scaled version of the GDP & Population, 
#le$GDP_scaled = scale(le$GDP)
#le$Population_scaled = scale(le$Population)
# Remove the unreliable column 
le <- subset(le,select=-c(percentage.expenditure))
```

```{r, include=FALSE}
# Null Data Handling
library(magrittr) 
library(dplyr)  
library(tidyr)
le %>% group_by(Country) %>% summarise(COUNT = n())
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Null Data Analysis
library(magrittr) 
library(dplyr)  
library(tidyr)
missing.values <- le %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing))

```


```{r message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
library(gridExtra)
missing.values <- le %>%
  gather(key="key", value="val") %>%
  mutate(isna=is.na(val)) %>%
  group_by(key) %>%
  mutate(total=n()) %>%
  group_by(key,total,isna) %>%
  summarise(num.isna=n()) %>%
  mutate(pct=num.isna/total * 100)
levels <- (missing.values%>%filter(isna==T) %>% arrange(desc(pct)))$key
null_percentage.plot <- missing.values %>% ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), stat='identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('dodgerblue2', 'coral'), 
                        labels = c("Present", "Missing")) +
      coord_flip() + labs(title = "Percentage of missing values", 
                          x = 'Features', y = "% of missing values")
null_inrow.plot <- le %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('dodgerblue2', 'coral'),
        labels = c("Present", "Missing")) +
    scale_x_discrete(limits = levels) +
    labs(x = "Features", y = "Row Number", title = "Missing values in rows") +
    coord_flip()
library(dplyr)
#le_dropped <- le %>% filter_at(vars(Population_scaled,Population,GDP,GDP_scaled,Income.composition.of.resources,Schooling),any_vars(!is.na(.)))
le_dropped <- le %>% filter_at(vars(Population,GDP,Income.composition.of.resources,Schooling),any_vars(!is.na(.)))
missing.values <- le_dropped %>%
  gather(key="key", value="val") %>%
  mutate(isna=is.na(val)) %>%
  group_by(key) %>%
  mutate(total=n()) %>%
  group_by(key,total,isna) %>%
  summarise(num.isna=n()) %>%
  mutate(pct=num.isna/total * 100)
#missing.values
levels <- (missing.values%>%filter(isna==T) %>% arrange(desc(pct)))$key
null_percentage_dropped.plot <- missing.values %>% ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), stat='identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('dodgerblue2', 'coral'), 
                        labels = c("Present", "Missing")) +
      coord_flip() + labs(title = "Percentage of missing values after dropping some common null value records", 
                          x = 'Features', y = "% of missing values")
null_inrow_dropped.plot <- le_dropped %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('dodgerblue2', 'coral'),
        labels = c("Present", "Missing")) +
    scale_x_discrete(limits = levels) +
    labs(x = "Features", y = "Row Number", title = "Missing values in rows after dropping some common null value records") +
    coord_flip()

#options(repr.plot.width = 30, repr.plot.height = 30)
#gridExtra::grid.arrange(null_percentage.plot, null_inrow.plot, ncol = 1)
#gridExtra::grid.arrange(null_percentage_dropped.plot, null_inrow_dropped.plot, ncol = 1)

```


<!-- Check how much records do each country have:  -->
```{r message=FALSE, warning=FALSE, include=FALSE}
le %>% group_by(Country) %>% summarise(COUNT = n())
le_dropped %>% group_by(Country) %>% summarise(COUNT = n()) #12 country were removed after dropping some common null value (193-181)
#might need to consider not using this variable 
```


```{r message=FALSE, warning=FALSE, include=FALSE}
for(i in 1:ncol(le_dropped)) {                                   # Replace NA in all columns
  le_dropped[ , i][is.na(le_dropped[ , i])] <- mean(le_dropped[ , i], na.rm = TRUE)
}
```


```{r, eval=FALSE, fig.height=2, fig.width=2, message=FALSE, warning=FALSE, include=FALSE}
library(ggplot2)
#install.packages("tidyverse")
library(tidyverse)
par(mfrow=c(1,2))
le_dropped %>%
  group_by(Year) %>%
  summarise(Life.expectancy = mean(Life.expectancy)) %>%
  ggplot(aes(x=Year,
             y=Life.expectancy)) +    
  geom_line()

le_dropped %>%
  group_by(Status) %>%
  summarise(Life.expectancy = mean(Life.expectancy)) %>%
  ggplot(aes(x=Status,
             y=Life.expectancy,
             fill=Status)) +    
  geom_bar(stat = "identity")+ scale_fill_manual(values=c('dodgerblue2', 'coral'))

```


```{r, eval=FALSE, fig.height=2, message=FALSE, warning=FALSE, include=FALSE}
le_dropped.pivot <- pivot_longer(le_dropped,c(Adult.Mortality,under.five.deaths,infant.deaths),names_to='Mortality.Group',values_to='Mortality.Rate')
require(gridExtra)

le_dropped.pivot.area <- le_dropped.pivot %>%
  group_by(Year,Mortality.Group) %>%
  summarise(Mortality.Rate = mean(Mortality.Rate)) %>%
  ggplot(aes(x=Year,
             y=Mortality.Rate,
             fill=Mortality.Group)) +
  geom_area(position="stack",stat="identity")

le_dropped.pivot.line <- le_dropped.pivot %>%
  group_by(Year,Mortality.Group) %>%
  summarise(Mortality.Rate = mean(Mortality.Rate)) %>%
  ggplot(aes(x=Year,
             y=Mortality.Rate,
             color=Mortality.Group)) +
  geom_line()

grid.arrange(le_dropped.pivot.area,le_dropped.pivot.line, ncol=2)
```


```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
head(le_dropped)
```

```{r warning=FALSE, include=FALSE}

#df = subset(le_dropped, select = -c(Country,GDP,Population) )
df = subset(le_dropped, select = -c(Country,Status.val) )
head(df)

```


```{r message=FALSE, warning=FALSE, echo=FALSE}

#install.packages(GGally)
library(GGally)
ggcorr(df,palette = "RdBu", size=2,label=TRUE,label_size = 2,hjust = .95,layout.exp=2)

```


### Variables Selection
Due to the above correlations between certain variables, in addition to a large number of variables in our model, a variable selection is conducted to remove some correlated variables and attain a simpler model via variable selection.   A BIC backward step model selection method has been applied to the dataset, with the following summary :

|Models           |No. of Variables |AIC Score    |Adj R-squared Score|
|-----            |-----            |-----        |-----|       
|Original Model   |20               |7642.14      |0.8299|
|Reduced Model    |12               |7604.24      |0.8296|

The reduced model now contains the following variables : Adult.Mortality + infant.deaths + Hepatitis.B + BMI + under.five.deaths + Polio + Diphtheria + HIV.AIDS + GDP + thinness..1.19.years + Income.composition.of.resources + Schooling

The number of independent variables are now effectively reduced to 12, together with a lower AIC score of 7604.34. Meanwhile, the adjusted R-squared score is well kept at nearly the same level as in the original model.  We are satisfied with the performance of this reduced model.  This reduced model will therefore be adopted as the basis for further analysis in this report.

```{r message=FALSE, warning=FALSE, include=FALSE}
#### Full model summary and diagnostics
lmmod <- lm(Life.expectancy~., data = df)
summary(lmmod)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
model.step.bic <- step(lmmod,k=log(nrow(df)))
summary(model.step.bic)
```


```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(car)
vif(model.step.bic)

#removed one of infant.deaths or under.five.deaths
```


```{r message=FALSE, warning=FALSE, include=FALSE}
df1<-df[,c('Life.expectancy','Adult.Mortality','infant.deaths','under.five.deaths',
      'Hepatitis.B','BMI','Polio','Diphtheria',
      'HIV.AIDS','thinness..1.19.years','Income.composition.of.resources','Schooling','GDP')]

# df1$Status <- factor(df1$Status)
# removed 'under.five.deaths', due to vif - multi collinearity from BIC selection but it decreased model
#  performance so should we retain it?
#head(df1)
```



```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#not carrying forward any clustering analysis for the first release of the report due to time
#constraints
library(mclust)
clus1 <- Mclust(df1)
summary(clus1)
```
We eliminate the Status variable from the selected list of variables in the reduced model as this is a factor variable with two statuses and not continuous. We first study the effect of the model without this variable. 

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(car)
lmmod2 <- lm(Life.expectancy~.,data=df1)
summary(lmmod2)
vif(lmmod2)

### End of EDA
### Start of model building and assessments
```


## Part 3. Regression Analysis


### Linear model and diagnostics

The initial model shows that we are able to explain approximately 82% of variability of our response variable using the selected predictor variables. The next step is to look at the error diagnostics from the model.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow=c(1,2),heights=c(1,1,1,1))
plot(lmmod2)
```
The QQ plot suggests that the model is heavy tailed and the data on both ends of the quantiles do not fit on a straight line. This is an indication that the current linear regression based model is not fitting the data well. Based on this, we undertake some additional testing to validate if the model is adequate and valid


#### a. Life expectancy variable distribution


```{r}

#Histogram & QQPlot
par(mfrow=c(1,2)) 
# hist_bin_width = 4
h <- hist(df$Life.expectancy, col='steelblue', main='Life.expectancy Histogram', breaks = 35)
#not really a good "bell-shape"
# install.packages("ggpubr")
plot(lmmod2,which = 2)
#S #most of the data is not fall along a straight diagonal line 
#qqline(df$Life.expectancy)

#Both are indicating that our predict variable Y "df$Life.expectancy" is not normally distributed 
```
From the histogram, it can be noticed that the response variable life expectancy is not normally distributed. From the plot, it also seems like a bimodal distribution of life expectancy data in the dataset.

#### b. Normal distribution test for our y variable 

Next, we evaluate to confirm if the response variable is normally distributed using Shapiro-Wilk test. The test has a p-value that is very small and is less than 0.05, this indicates that our response variable if not normally distributed. 

```{r}
#Shapiro-Wilk Test

shapiro.test(df$Life.expectancy)

#Finding: Since df$Life.expectancy p-value is less than .05, indicate that our y variable is not normally distributed!!!
```

#### c. Parametric model specification tests
Another test to see if the above parametric model specification is correct.
```{r}
library(lmtest)
resettest(lmmod2)
```

#### d. np specification test

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#LM with matching dependent variable with npreg
model_lm <- lm(Life.expectancy~Adult.Mortality + infant.deaths + Hepatitis.B + BMI + under.five.deaths + Polio + Diphtheria + HIV.AIDS + GDP + thinness..1.19.years + Income.composition.of.resources + Schooling, data = df, x=TRUE, y=TRUE)
summary(model_lm)
```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# X <- data.frame(df$Adult.Mortality,df$infant.deaths,df$Hepatitis.B,df$BMI,df$under.five.deaths,df$Polio,df$Diphtheria,df$HIV.AIDS,df$GDP,df$thinness..1.19.years,df$Income.composition.of.resources,df$Schooling)
# 
# result_npcms <- npcmstest(model=model_lm, xdat=X, ydat=df$Life.expectancy) #33Hours to run
```

```{r echo=FALSE}
# result_npcms

# objects()
# find("result_npcms")
# 
# saveRDS(result_npcms,"result_npcms.rds")
result_npcms <- readRDS("result_npcms.rds") #PreTrained Model
summary(result_npcms)
```



All the diagnostic tests indicate that linear regression is not an appropriate model for the given data as assumptions for the model are violated.


### Parametric model and assessments

As the linear model is not adequate, we move on to model this with other models that do not assume normal distribution. The models selected for the given dataset are LASSO and Neural Net with  linear activation function. The following variables are selected for rest of the modeling based on correlation of the variables with the response variable and our knowledge on the domain. Here is a summary of the variable selection and our comments.


|  **Data Categories**   |    **Vaiables**                                                                              |
|------------------------|----------------------------------------------------------------------------------------------|
| **Economical Data**    | Total expenditure, Percentage expenditure, GDP, Income composition of resources              |
| **Social Data**        | Country, Status, Population, Schooling, Alcohol, BMI, Thinness 1-19 years, Thinness 5-9 years|
| **Mortality Data**     | Adult Mortality, Infant deaths, Under-five deaths                                            |
| **Immunization Data**  | Hepatitis B, Measles, Polio, HIV/AIDS, BMI, Diphtheria                                       |

| **Column Name **                  | **Type **       | **LM ** | **LASSO ** | **NN ** | **NPREG ** | **Reason of Removal**                                                       |
|----------------------------------|--------------|--------|-----------|--------|-----------|-----------------------------------------------------------------------------|
| Country                          | (Discrete)   |        |           |        |           | Since we wanted to build models for all countries                           |
| Year                             | (Discrete)   |        |           |        |           | ordinal type data and based on domain knowledge, not consider important     |
| Status                           | (Discrete)   |        |           |        |           | nominal type data and based on domain knowledge, not consider important     |
| Adult Mortality                  | (Discrete)   | X      | X         |X       | X         |                                                                             |
| Infant deaths                    | (Discrete)   | X      | X         |X       | X         |                                                                             |
| Under-five deaths                | (Discrete)   | X      | X         |X       | X         |                                                                             |
| Hepatitis B                      | (Continuous) | X      | X         |X       | X         |                                                                             |
| Measles                          | (Discrete)   |        |           |        |           | Since it is a count and discrete type data and weak correlation with our predictor                  |
| Polio                            | (Continuous) | X      | X         |X       | X         |                                                                             |
| Diphtheria                       | (Continuous) | X      | X         |X       | X         |                                                                             |
| Total Expenditure                | (Continuous) |        |           |        |           | based on domain knowledge, not consider important                           |
| Percentage Expenditure           | (Continuous) |        |           |        |           | based on domain knowledge, not consider important                           |
| GDP                              | (Continuous) | X      | X         |X       | X         |                                                                             |
| Population                       | (Discrete)   |        |           |        |           | no correlation with our predictor indicated by our correlation plot         |
| Income composition of resources  | (Continuous) | X      | X         |X       | X         |                                                                             |
| Schooling                        | (Continuous) | X      | X         |X       | X         |                                                                             |
| Alchol                           | (Continuous) |        |           |        |           | based on domain knowledge, not consider important                           |
| HIV/AIDS                         | (Continuous) | X      | X         |X       | X         |                                                                             |
| BMI                              | (Continuous) | X      | X         |X       | X         |                                                                             |
| Thinness 1-19 years              | (Continuous) | X      | X         |X       | X         |                                                                             |
| Thinness 5-9 years               | (Continuous) |        |           |        |           | range already covered in 1-19 Thinness 1-19 years                           |
| status.val                       | (Continuous) |        |           |        |           | based on domain knowledge, not consider important                           |


Two different supervised algorithms tried on the dataset. They do not have the constraint of a normal distribution for response variable.

First did a train and test split so we can measure the MSE and compare how each of the models are performing in terms of minimizing MSE.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(glmnet)
# approximately 70:30 split for train and test

df1<-df[,c('Life.expectancy','Adult.Mortality','infant.deaths','under.five.deaths',
      'Hepatitis.B','BMI','Polio','Diphtheria',
      'HIV.AIDS','thinness..1.19.years','Income.composition.of.resources','Schooling','GDP')]

ind <- sample(1:nrow(df1), 2000)
traino <- df1[ind,]
testo <- df1[-ind,]
```



```{r message=FALSE, warning=FALSE, include=FALSE}
#linear model for comparison
lmmodtr <- lm(traino[,1]~.,data=traino[,-1],x=TRUE, y=TRUE)
summary(lmmodtr)

```

```{r message=FALSE, warning=FALSE, include=FALSE}
#LASSO
library(glmnet)
y <- traino$Life.expectancy
x <- data.matrix(traino[,-1])
#k-fold cross-validation to find optimal lambda value\
#cv default is 10 fold
cv_model <- cv.glmnet(x, y, alpha = 1)

#optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
plot(cv_model) 

#coefficients of best model
lasmod <- glmnet(as.matrix(traino[,-1]),traino$Life.expectancy, alpha = 1, lambda = best_lambda)
coef(lasmod)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
#linear model
mselm_te1 <- mean((testo[,1]-predict(lmmodtr, newdata=testo))^2)

#lasso
mselas_te1 <- mean((testo[,1]-predict(lasmod, newx=as.matrix(testo[,-1])))^2)

```

```{r message=FALSE, warning=FALSE, include=FALSE}
library(nnet)
#18 MSE
hidden <- 0
nnmse <- 0
for(i in 1:62){
  
  set.seed(4521)
  
  train_lin <- nnet(traino[,1]~., data=traino, size=i, linout=TRUE, trace=FALSE)
#calculating mse

  mse_nnet_lin <- mean((testo[,1]-(predict(train_lin, newdata=testo)))^2)
  hidden[i] <- i
  nnmse[i] <- mse_nnet_lin
  #print(paste("Number of hidden layer variables:", i))
  #print(paste("MSE:",mse_nnet_lin))
  
}
```

Test MSE comparison for the three models

|           | **LM**   | **LASSO** | **NN**   |
|-----------|----------|-----------|----------|
| **PRESS** | 15.93367 | 15.98972  | 22.43056 |

```{r}
# #MSE comparison
# print(mselm_te1)
# print(mselas_te1)
# print(min(mse_nnet_lin))

```
Test R2 comparison for the three models

|        | **LM**            | **LASSO**         |
|--------|-------------------|-------------------|
| **R2** | 0.829139273435324 | 0.829061931452822 |

```{r}
# #Linear Model R2
# r2_lm<- summary(lmmodtr)$r.squared
# paste("Linear Model R2: ",r2_lm)
# 
# #Lasso R2
# r2_lasso <- lasmod$dev.ratio
# paste("Lasso R2: ",r2_lasso)

```


As we compare linear model, lasso and neural net, we see that the test MSE is minimum for LASSO model. So this is a model that can be considered for the dataset.

### Nonparametric regression

The response variable shows a bimodal distribution and nonparametric regression performs better on such datasets per literature. We next try non parametric regression on the dataset.



```{r cache=TRUE}
library(np)
# n <- names(df)
# f <- as.formula(paste("df$Life.expectancy ~", paste(n[!n %in% "Life.expectancy"], collapse = " + ")))
# 
# model_np <- npregbw(Life.expectancy ~ Adult.Mortality + infant.deaths + Hepatitis.B + BMI + under.five.deaths + Polio + Diphtheria + HIV.AIDS + GDP + thinness..1.19.years + Income.composition.of.resources + Schooling, data = df, regtype="ll", bwmethod = "cv.aic")    #19 HRs to run...

# model_np <- npreg(bws = model_np)
# summary(model_np)
model_np <- readRDS("model_np.rds") #PreTrained Model
summary(model_np)
```
We see that the R^2 is increased to 87% approximately. Done with local linear estimator and cv.aic. This is a cross validated model and help estimate the long run performance. Can we see BIC? 

```{r cache=TRUE}
#npsigtest_npreg <- npsigtest(model_np)    #10 HRs to run...
```
![npsigtest_npreg result](dataset/npsigtest_npreg.png)

We measure the significance of the variables for a parsimonious model. All the parameters used are significant.


Summarizing the different models and the performance assessed during the course of this project
#### Add table

## Model improvements

1. status variable and other ordinal, nominal variables
2. train and test split for np, but what we have now is sufficient for measuring long run performance
3. multicollinearity between the variables infant.deaths and under.five.deaths. Remove one of the variables and study if there are improvements in performance
4. measure without imputing data

## Challenges
1. 30 hours for npreg
2. 30+ hours for model significance
3. null values in the dataset, columns dropped - , columns imputed with mean - 

## Conclusion
np and LASSO are suitable for this dataset. We find that life expectancy is....






