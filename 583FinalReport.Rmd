---
title: "Data 583 Life Expectancy (WHO)"
author: "Justin Chan, Kenny Tong, Viji Rajagopalan"
date: "22 Mar, 2023"
output:
  pdf_document: default
  html_document:
    df_print: paged
fontsize: 10pt
geometry: margin=2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data 583 Life Expectancy - Final Report (Life Expectancy Data)

## 1. Introduction and Hypotheses
Life expectancy has always been an area of interest for humanity. The key to long live has remained an intriguing topic to people for decades.  The goal of this project is to study a dataset that contains information on life expectancy and identify some of the variables that significantly impact life expectancy. 

The dataset chosen for the study has life expectancy data of 193 countries between 2000-2015, together with different predictive factors. Broadly speaking, predicting variables are categorized into 4 major areas : Immunization, Mortality, Economical, and Social, containing a total of 21 individual  variables. Our hypothesis is that a subset of variables from this dataset would be able to explain and predict life expectancy with good accuracy (say > 80%). The dataset has a mix of variable types â€“ continuous and discrete. Within discrete type, some variables are ordered, and some are unordered categorical variables. 

With such a mix and complexity of data, we also hypothesize that all variables will not share a simple linear relationship with the predictor variable and modelling of life expectancy will require a more complex model. We analyze and validate several statistical models throughout the report with the primary goal of identifying an adequate model for the dataset.


## 2. Dataset overview

### 2.1 Variables Summary and Categories
Life expectancy is the response variable in this dataset.  This represents the mean life expectancy (in age) by specific country and year combination. Refer **Table 1** and **Table 2** below for the list of predictor variables and their categories.

The dataset contains 2563 missing values in various columns.  To handle the NA values in the dataset, two simple strategies are used.  Firstly, 12 countries that have more NA values within their records are removed from the dataset.  Secondly, the remaining NA records are imputed by the respective column mean.

Two columns are removed from the original dataset. The 'Percentage expenditure' variable is removed from the entire assessment as the values present in this column are unclear. Another variable 'country' is also removed because we intend to focus on studying the life expectancy on a global basis.
\newpage

|**Variable**     |**Unit of Measurement/Data Category**    | **Continuous vs Discrete** |   **Variable**     |**Unit of Measurement/Data Category**    | **Continuous vs Discrete** |
|-----        |-----                                | ----- |   -----        |-----                                | ----- |
|**Life Expectancy** |Years Old (Age)                   |Continuous  |**Total expenditure**|Percentage                       |Continuous|
|**Country**      |Nominal Data                         |Discrete  |**Percentage expenditure**|Percentage                  |Continuous|
|**Year**         |Ordinal Data                         |Discrete  |**GDP**          |Currency (USD)                       |Continuous|
|**Status**       |Nominal Data                         |Discrete  |**Population**   |Count                                |Discrete|
|**Adult Mortality**|Count Data                         |Discrete  |**Income composition of resources**|Percentage         |Continuous|
|**Infant deaths**|Count Data                           |Discrete  |**Schooling**    |Mean (Years)                         |Continuous|
|**Under-five deaths**|Count Data                       |Discrete  |**Alcohol**      |Litres                               |Continuous|
|**Hepatitis B**  |Percentage                           |Continuous  |**HIV/AIDS**     |Percentage                           |Continuous|
|**Measles**      |Count Data                           |Discrete  |**BMI**          |Average BMI                          |Continuous|
|**Polio**        |Percentage                           |Continuous  |**Thinness 1-19 years**|Percentage                     |Continuous|
|**Diphtheria**   |Percentage                           |Continuous  |**Thinness 5-9 years**|Percentage                      |Continuous|

\begin{center}
Table 1 : List of Predictor Variables
\end{center}

Following table shows how the above variables are grouped based on the 4 categories.

|  **Data Categories**   |    **Variables**                                                                              |
|------------------------|----------------------------------------------------------------------------------------------|
| **Economical Data**    | Total expenditure, Percentage expenditure, GDP, Income composition of resources              |
| **Social Data**        | Country, Status, Population, Schooling, Alcohol, BMI, Thinness 1-19 years, Thinness 5-9 years, BMI|
| **Mortality Data**     | Adult Mortality, Infant deaths, Under-five deaths                                            |
| **Immunization Data**  | Hepatitis B, Measles, Polio, HIV/AIDS, Diphtheria                                       |

\begin{center}
Table 2 : Variable Categories
\end{center}

```{r, include=FALSE}
### Start of EDA section - retained in Rmd

le <- read.csv("dataset/LifeExpectancy.csv")

# Create a new column Status.val to represent the Status column with number
le$Status.val <- ifelse(le$Status == "Developed",1,0)
# Create a new column as the scaled version of the GDP & Population, 
#le$GDP_scaled = scale(le$GDP)
#le$Population_scaled = scale(le$Population)
# Remove the unreliable column 
le <- subset(le,select=-c(percentage.expenditure))
```

```{r, include=FALSE}
# Null Data Handling
library(magrittr) 
library(dplyr)  
library(tidyr)
le %>% group_by(Country) %>% summarise(COUNT = n())
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Null Data Analysis
library(magrittr) 
library(dplyr)  
library(tidyr)
missing.values <- le %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing))

```


```{r message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
library(gridExtra)
missing.values <- le %>%
  gather(key="key", value="val") %>%
  mutate(isna=is.na(val)) %>%
  group_by(key) %>%
  mutate(total=n()) %>%
  group_by(key,total,isna) %>%
  summarise(num.isna=n()) %>%
  mutate(pct=num.isna/total * 100)
levels <- (missing.values%>%filter(isna==T) %>% arrange(desc(pct)))$key
null_percentage.plot <- missing.values %>% ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), stat='identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('dodgerblue2', 'coral'), 
                        labels = c("Present", "Missing")) +
      coord_flip() + labs(title = "Percentage of missing values", 
                          x = 'Features', y = "% of missing values")
null_inrow.plot <- le %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('dodgerblue2', 'coral'),
        labels = c("Present", "Missing")) +
    scale_x_discrete(limits = levels) +
    labs(x = "Features", y = "Row Number", title = "Missing values in rows") +
    coord_flip()
library(dplyr)
#le_dropped <- le %>% filter_at(vars(Population_scaled,Population,GDP,GDP_scaled,Income.composition.of.resources,Schooling),any_vars(!is.na(.)))
le_dropped <- le %>% filter_at(vars(Population,GDP,Income.composition.of.resources,Schooling),any_vars(!is.na(.)))
missing.values <- le_dropped %>%
  gather(key="key", value="val") %>%
  mutate(isna=is.na(val)) %>%
  group_by(key) %>%
  mutate(total=n()) %>%
  group_by(key,total,isna) %>%
  summarise(num.isna=n()) %>%
  mutate(pct=num.isna/total * 100)
#missing.values
levels <- (missing.values%>%filter(isna==T) %>% arrange(desc(pct)))$key
null_percentage_dropped.plot <- missing.values %>% ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), stat='identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('dodgerblue2', 'coral'), 
                        labels = c("Present", "Missing")) +
      coord_flip() + labs(title = "Percentage of missing values after dropping some common null value records", 
                          x = 'Features', y = "% of missing values")
null_inrow_dropped.plot <- le_dropped %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('dodgerblue2', 'coral'),
        labels = c("Present", "Missing")) +
    scale_x_discrete(limits = levels) +
    labs(x = "Features", y = "Row Number", title = "Missing values in rows after dropping some common null value records") +
    coord_flip()

#options(repr.plot.width = 30, repr.plot.height = 30)
#gridExtra::grid.arrange(null_percentage.plot, null_inrow.plot, ncol = 1)
#gridExtra::grid.arrange(null_percentage_dropped.plot, null_inrow_dropped.plot, ncol = 1)

```


<!-- Check how much records do each country have:  -->
```{r message=FALSE, warning=FALSE, include=FALSE}
le %>% group_by(Country) %>% summarise(COUNT = n())
le_dropped %>% group_by(Country) %>% summarise(COUNT = n()) #12 country were removed after dropping some common null value (193-181)
#might need to consider not using this variable 
```


```{r message=FALSE, warning=FALSE, include=FALSE}
for(i in 1:ncol(le_dropped)) {                                   # Replace NA in all columns
  le_dropped[ , i][is.na(le_dropped[ , i])] <- mean(le_dropped[ , i], na.rm = TRUE)
}
```


```{r, fig.height=2, fig.width=2, message=FALSE, warning=FALSE, include=FALSE}
library(ggplot2)
#install.packages("tidyverse")
library(tidyverse)
par(mfrow=c(1,2))
le_dropped %>%
  group_by(Year) %>%
  summarise(Life.expectancy = mean(Life.expectancy)) %>%
  ggplot(aes(x=Year,
             y=Life.expectancy)) +    
  geom_line()

le_dropped %>%
  group_by(Status) %>%
  summarise(Life.expectancy = mean(Life.expectancy)) %>%
  ggplot(aes(x=Status,
             y=Life.expectancy,
             fill=Status)) +    
  geom_bar(stat = "identity")+ scale_fill_manual(values=c('dodgerblue2', 'coral'))

```


```{r, fig.height=2, message=FALSE, warning=FALSE, include=FALSE}
le_dropped.pivot <- pivot_longer(le_dropped,c(Adult.Mortality,under.five.deaths,infant.deaths),names_to='Mortality.Group',values_to='Mortality.Rate')
require(gridExtra)

le_dropped.pivot.area <- le_dropped.pivot %>%
  group_by(Year,Mortality.Group) %>%
  summarise(Mortality.Rate = mean(Mortality.Rate)) %>%
  ggplot(aes(x=Year,
             y=Mortality.Rate,
             fill=Mortality.Group)) +
  geom_area(position="stack",stat="identity")

le_dropped.pivot.line <- le_dropped.pivot %>%
  group_by(Year,Mortality.Group) %>%
  summarise(Mortality.Rate = mean(Mortality.Rate)) %>%
  ggplot(aes(x=Year,
             y=Mortality.Rate,
             color=Mortality.Group)) +
  geom_line()

grid.arrange(le_dropped.pivot.area,le_dropped.pivot.line, ncol=2)
```


```{r, message=FALSE, warning=FALSE, include=FALSE}
head(le_dropped)
```

```{r warning=FALSE, include=FALSE}

#df = subset(le_dropped, select = -c(Country,GDP,Population) )
df = subset(le_dropped, select = -c(Country,Status.val) )
head(df)

```

The resulting dataset are then studied closely to understand their correlation effects with the response variable life expectancy. Following plot **Correlation Matrix Plot** is a correlation matrix on all the variables in the dataset.

```{r message=FALSE, warning=FALSE, echo=FALSE,fig.align = 'center'}

#install.packages(GGally)
library(GGally)
ggcorr(df,palette = "RdBu", size=2,label=TRUE,label_size = 2,hjust = .95,layout.exp=2)+labs(title = "Correlation Matrix Plot", title.size=1,title.hjust=0.5)

```

It can be noted that the response variable life expectancy is highly correlated with income composition, schooling and adult mortality variables and has a correlation value of $0.7$, $0.7$ and $-0.7$ respectively. Life expectancy is moderately correlated with variables BMI, Polio, Diphtheria, HIV.AIDS and thinness variables and has a correlation value of $0.6$, $0.5$, $0.5$, $-0.6$, $-0.5$.

### 2.2 Initial analysis using linear regression
Life expectancy is a continuous variable and the first choice is building a linear regression model which is simple and interpretable. A BIC backward step model variable selection method is also applied on the full model to arrive at a parsimonious model containing only significant predictor variables. Following table **Table 3** provides a summary of the two models.



|**Models**           |**No. of Variables** |**Adj R-squared Score**|
|-----            |-----            |-----|       
|**Original Model**   |20               |0.8299|
|**Reduced Model**    |12               |0.8296|

\begin{center}
Table 3 :Original vs Reduced Models
\end{center}

The number of independent variables is now effectively reduced to 12 and the reduced model contains the following 12 variables : Adult.Mortality + infant.deaths + Hepatitis.B + BMI + under.five.deaths + Polio + Diphtheria + HIV.AIDS + GDP + thinness..1.19.years + Income.composition.of.resources + Schooling. The adjusted R-squared score is well kept at nearly the same level as in the original model.  The reduced model is able to explain more than 82% of variation in the response variable and its performance is above the anticipated 80%. 

To conclude, the reduced model from this step is selected as the first model for the dataset.  The dataset now has `r nrow(df)` records and 12 columns. It is used for further evaluation from a linear model stand point and will be referred to as linear model in the remainder of the discussion. 

```{r message=FALSE, warning=FALSE, include=FALSE}
#### Full model summary and diagnostics
lmmod <- lm(Life.expectancy~., data = df)
summary(lmmod)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
model.step.bic <- step(lmmod,k=log(nrow(df)))
summary(model.step.bic)
```



```{r message=FALSE, warning=FALSE, include=FALSE}
df1<-df[,c('Life.expectancy','Adult.Mortality','infant.deaths','under.five.deaths',
      'Hepatitis.B','BMI','Polio','Diphtheria',
      'HIV.AIDS','thinness..1.19.years','Income.composition.of.resources','Schooling','GDP')]

# df1$Status <- factor(df1$Status)
# removed 'under.five.deaths', due to vif - multi collinearity from BIC selection but it decreased model
#  performance so should we retain it?
#head(df1)
```



```{r, message=FALSE, warning=FALSE, include=FALSE}
#not carrying forward any clustering analysis for the first release of the report due to time
#constraints
#library(mclust)
#clus1 <- Mclust(df1)
#summary(clus1)
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(car)
lmmod2 <- lm(Life.expectancy~.,data=df1)
summary(lmmod2)
vif(lmmod2)

### End of EDA
### Start of model building and assessments
```


## 3. Regression Analysis


### 3.1 Linear model and diagnostics

The linear model shows that we are able to explain approximately 82% of variability of our response variable using the selected predictor variables. The next step is to look at the error diagnostics from the model.

```{r,echo=FALSE,results='markup',fig.align = 'center'}
par(mfrow=c(2,2))

plot(lmmod2)
mtext("Diagnostic Plots for Linear Regression Analysis", side = 3, line = -1, outer = TRUE)

```

From the above diagnostic plots, the **Residual vs Fitted** and **Scale-Location** plots show a horizontal red line which indicate that the variance of the residual is same for different values of predictor variables. The **Residuals vs Leverage** plot shows some points with high residues and as the points are within cook's distance of 0.5, no records need to be eliminated. The **Normal Q-Q plot** suggests that the model is heavy tailed and the data on both ends of the quantiles do not fit on a straight line. This is an indication that the current linear regression based model is not fitting the data well and that the response variable is not normally distributed. Based on this, we undertake additional testing to validate if the model is adequate and valid.



\newpage
#### a. Life expectancy variable distribution


```{r,echo=FALSE,results='markup',fig.align = 'center', fig.width = 8, fig.asp = .62}
plot_den1<-densityPlot(~ Life.expectancy, show.bw=TRUE, method="kernel", data = df, xlab="age", ylab="Life.expectancy")
title(main="Life expectancy distribution density plot",font.main= 1)
polygon(plot_den1, col = rgb(0.78, 0.89, 1, alpha = 0.6))

qqnorm(df$Life.expectancy)
qqline(df$Life.expectancy, col = "red", lwd = 2)

```
\newpage
From the **Density plot** above, it can be seen that the mean of the distribution isn't symmetrical and the mean isn't centered at 0, indicating the response variable life expectancy is not normally distributed. From the **Normal QQ plot** of the regression model, it can be observed that there is a distinct curve in the middle of plot rather than a straight line, this indicates that there could be a bimodal distribution to response variable. These observations necessitate validation of distribution of the response variable.


#### b. Normal distribution test for response variable 

Shapiro-Wilk test is a statistical test for normality and a p-value that is very small and is less than 0.05 proves the variable in consideration is not normally distributed. Shapiro-Wilk test on the response variable life expectancy resulted in a p-value of < 2.2e-16.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
#Shapiro-Wilk Test

shapiro.test(df$Life.expectancy)

#Finding: Since df$Life.expectancy p-value is less than .05, indicate that our y variable is not normally distributed!!!
```
This proves the response variable is not normally distributed and additionally, hypothesis tests for validating correct specification of parametric MLR models are conducted to identify if the selected linear model specification is valid for the given dataset.


#### c. Parametric model specification test

Ramsey's RESET test is a test conducted to validate the correctness of the functional form. A p-value that is very small and is less than $0.05$ rejects that the functional form is correctly specified. RESET test is conducted on the linear model and the resulting p-value is $< 2.2e-16$.

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
library(lmtest)
resettest(lmmod2)
```
Based on the test, the linear model is rejected as the correct functional form for modelling the underlying data.

#### d. Consistent nonparametric inference

The consistent nonparametric inference test is a hypothesis test for correct specification of parametric MLR models. This allows to estimate if the functional for given parameter estimates is reasonable when compared. A p-value that is very small and is less than $0.05$ rejects that the functional form for given parameter estimates is reasonable.

```{r message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
#LM with matching dependent variable with npreg
model_lm <- lm(Life.expectancy~Adult.Mortality + infant.deaths + Hepatitis.B + BMI + under.five.deaths + Polio + Diphtheria + HIV.AIDS + GDP + thinness..1.19.years + Income.composition.of.resources + Schooling, data = df, x=TRUE, y=TRUE)
summary(model_lm)
```

```{r message=FALSE, warning=FALSE, echo=FALSE}
# X <- data.frame(df$Adult.Mortality,df$infant.deaths,df$Hepatitis.B,df$BMI,df$under.five.deaths,df$Polio,df$Diphtheria,df$HIV.AIDS,df$GDP,df$thinness..1.19.years,df$Income.composition.of.resources,df$Schooling)
# 
# result_npcms <- npcmstest(model=model_lm, xdat=X, ydat=df$Life.expectancy) #33Hours to run
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# result_npcms

# objects()
# find("result_npcms")
# 
# saveRDS(result_npcms,"result_npcms.rds")
result_npcms <- readRDS("result_npcms.rds") #PreTrained Model
summary(result_npcms)
```

As noted, the p-value for linear model is $< 2.22e-16$ and this output suggests that the linear model is rejected.

All the diagnostic tests indicate that linear regression is not an appropriate model for the given data. This proves one of the hypothesis of our project that a simple linear model may not be adequate in explaining the variability in the response variable life expectancy.


### 3.2 Parametric regression models and relative assessments

As the linear model is not adequate, we move on to other parametric regression models that do not assume normal distribution and known to perform well on complex and mixed data types. There are several models that could be used in the assessments and we selected LASSO and Neural Net with linear activation function for the given dataset. 

The following **Table 4** shows variables that are selected for rest of the modeling based on correlation of the variables with the response variable, our knowledge on the domain. The selection process also focuses on prioritizing continuous variables. Here is a summary of the variable selection and  comments describing the reason for removal of the variable. P.S: The variables not selected will be dealt with in subsequent runs to understand their significance and relationship with response variable.


| **Column Name **       | **Type **         | **Reason of Removal**|
|------------------------|-------------------|----------------------|
| Country                          | (Discrete)   | Build models for all countries|
| Year                             | (Discrete)   | Ordinal type data and based on domain knowledge, not prioritized     |
| Status                           | (Discrete)   | Nominal type data   |
| Adult Mortality                  | (Discrete)   | NA, Selected in first run|
| Infant deaths                    | (Discrete)   | NA, Selected in first run|
| Under-five deaths                | (Discrete)   | NA, Selected in first run|                           
| Hepatitis B                      | (Continuous) | NA, Selected in first run|                           
| Measles                          | (Discrete)   | Discrete type data and weak correlation with our predictor                  |
| Polio                            | (Continuous) | NA, Selected in first run|                           
| Diphtheria                       | (Continuous) | NA, Selected in first run|            
| Total Expenditure                | (Continuous) | Based on domain knowledge|
| Percentage Expenditure           | (Continuous) | Based on domain knowledge|                           
| GDP                              | (Continuous) | NA, Selected in first run|                           
| Population                       | (Discrete)   | No correlation with our predictor indicated by our correlation plot         |
| Income composition of resources  | (Continuous) | NA, Selected in first run|                           
| Schooling                        | (Continuous) | NA, Selected in first run|                           
| Alcohol                          | (Continuous) | Based on domain knowledge|    
| HIV/AIDS                         | (Continuous) | NA, Selected in first run|                           
| BMI                              | (Continuous) | NA, Selected in first run|                           
| Thinness 1-19 years              | (Continuous) | NA, Selected in first run|
| Thinness 5-9 years               | (Continuous) | Range already covered in 1-19 Thinness 1-19 years|   

\begin{center}
Table 4 : Variable selection for parametric and nonparametric models
\end{center}

First, the dataset is divided into a train and test datasets with an approximate $70%-30%$ of the complete data using a random sampling process so long run performance of the models can be estimated. The train dataset has 2000 records and test dataset has 778 records in total.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(glmnet)
# approximately 70:30 split for train and test

df1<-df[,c('Life.expectancy','Adult.Mortality','infant.deaths','under.five.deaths',
      'Hepatitis.B','BMI','Polio','Diphtheria',
      'HIV.AIDS','thinness..1.19.years','Income.composition.of.resources','Schooling','GDP')]

ind <- sample(1:nrow(df1), 2000)
traino <- df1[ind,]
testo <- df1[-ind,]
```



```{r message=FALSE, warning=FALSE, include=FALSE}
#linear model for comparison
lmmodtr <- lm(traino[,1]~.,data=traino[,-1],x=TRUE, y=TRUE)
summary(lmmodtr)

```

```{r message=FALSE, warning=FALSE, include=FALSE, cache=TRUE}
#LASSO
library(glmnet)
y <- traino$Life.expectancy
x <- data.matrix(traino[,-1])
#k-fold cross-validation to find optimal lambda value\
#cv default is 10 fold
cv_model <- cv.glmnet(x, y, alpha = 1)

#optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
plot(cv_model) 

#coefficients of best model
lasmod <- glmnet(as.matrix(traino[,-1]),traino$Life.expectancy, alpha = 1, lambda = best_lambda)
coef(lasmod)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
#linear model
mselm_te1 <- mean((testo[,1]-predict(lmmodtr, newdata=testo))^2)

#lasso
mselas_te1 <- mean((testo[,1]-predict(lasmod, newx=as.matrix(testo[,-1])))^2)

```

```{r message=FALSE, warning=FALSE, include=FALSE}
library(nnet)
#18 MSE
hidden <- 0
nnmse <- 0
for(i in 1:62){
  
  set.seed(4521)
  
  train_lin <- nnet(traino[,1]~., data=traino, size=i, linout=TRUE, trace=FALSE)
#calculating mse

  mse_nnet_lin <- mean((testo[,1]-(predict(train_lin, newdata=testo)))^2)
  hidden[i] <- i
  nnmse[i] <- mse_nnet_lin
  #print(paste("Number of hidden layer variables:", i))
  #print(paste("MSE:",mse_nnet_lin))
  
}
```

Three types of models using linear regression (LM), LASSO and NeuralNet with linear activation function are built on the $train$ dataset and the PRESS (Predicted Residual Error Sum of Squares) statistic is calculated using $test$ dataset to identify the best performing model. Following **Table 5** summarizes and compares the PRESS statistics.

|           | **LM**   | **LASSO** | **NN**   |
|-----------|----------|-----------|----------|
| **PRESS** | 15.93367 | 15.98972  | 22.43056 |

\begin{center}
Table 5 : PRESS statistics for parametric models
\end{center}

Based on the output, it can be seen that LM and LASSO models perform better than NeuralNet model for this dataset. P.S: Linear model is used in these assessments for benchmarking purposes and not for actual use as the model is not valid.

```{r include=FALSE}
# #MSE comparison
# print(mselm_te1)
# print(mselas_te1)
# print(min(mse_nnet_lin))

```

Selecting LM and LASSO, the $R^2$ is also measured for the models. It can be seen from **Table 6** that LASSO performs nearly at the same level as the linear model (LM).

|        | **LM**            | **LASSO**         |
|--------|-------------------|-------------------|
| **R2** | 0.829139273435324 | 0.829061931452822 |

\begin{center}
Table 6 : LM vs LASSO
\end{center}

```{r include=FALSE}
# #Linear Model R2
# r2_lm<- summary(lmmodtr)$r.squared
# paste("Linear Model R2: ",r2_lm)
# 
# #Lasso R2
# r2_lasso <- lasmod$dev.ratio
# paste("Lasso R2: ",r2_lasso)

```


Based on these assessments, LASSO is a viable model that can be considered for this dataset that has approximately $82%$ for predicted R^2 value and meets the performance goals expectations. LASSO does not have assumptions on the error distribution so residuals are not validated.


### 3.3 Nonparametric regression

Nonparametric regression is considered as another good option for the complex and mixed dataset that is of interest here due to proven flexibility and adaptability nature of these models. One important difference between nonparametric model and rest of the parametric models is that the entire data is used in the model training process. The nonparametric regression is carried out with local linear estimator and cv.aic for automated bandwidth selection. This bandwidth selection method specifies expected Kullback-Leibler cross-validation (Hurvich, Simonoff, and Tsai (1998))and in general provides consistent estimates. 

```{r cache=TRUE, include=FALSE}
library(np)
# n <- names(df)
# f <- as.formula(paste("df$Life.expectancy ~", paste(n[!n %in% "Life.expectancy"], collapse = " + ")))
# 
# model_np <- npregbw(Life.expectancy ~ Adult.Mortality + infant.deaths + Hepatitis.B + BMI + under.five.deaths + Polio + Diphtheria + HIV.AIDS + GDP + thinness..1.19.years + Income.composition.of.resources + Schooling, data = df, regtype="ll", bwmethod = "cv.aic")    #19 HRs to run...

# model_np <- npreg(bws = model_np)
# summary(model_np)
model_np <- readRDS("model_np.rds") #PreTrained Model
summary(model_np)
```
The output of the nonparametric regression model indicates an $R^2$ value of 87% approximately. This is the summary measure of in-sample fit for the model lies in the range of [0,1]. 1 denotes a perfect fit to the sample data and 0 indicates no fit. This is the counterpart to $R^2$ of linear model.

We acknowledget that the $R^2$ for LASSO model is calculated based on a train vs test setup and nonparametric regression $R^2$ is calculated on the complete dataset and a nonparamertic train-test fitting is identified as a future scope item that will be looked into. As the nonparametric model is a cross validated model and can provide long run performance, the LASSO and nonparametric model coeffients are compared and summarized in the **Table 7** table below.

|        | **NPREG**            | **LASSO**         |
|--------|-------------------|-------------------|
| **R2** | 0.8722143         | 0.829061931452822 |

\begin{center}
Table 7 : Nonparametric vs LASSO based model comparison
\end{center}

The nonparametric model has a higher $R^2$ of 87%(approx) when compared to the parametric model $R^2$ of 83%(approx). So, it is concluded that nonparametric model fits the given dataset better and is selected among the assessed models for use.

In order to arrive at a more parsimonious model, significance of the variables used in nonparametric regression is measured and per below **Nonparametric model variable significance** output all the variables are significant and will be retained in the model. 

```{r message=FALSE, warning=FALSE, echo=FALSE}
#npsigtest_npreg <- npsigtest(model_np)    #10 HRs to run...
```
![Nonparametric model variable significance](dataset/npsigtest_npreg.png)

\newpage
#### a. Error Diagnostics
```{r ,fig.align = 'center', echo=FALSE}
res <- resid(model_np)
plot(fitted(model_np), res, xlab="Fitted values(Life.expectancy)", ylab="Residual")
title(main="Residual vs Fitted plot",font.main= 1)
abline(0,0, col="red")
```
**Residual vs Fitted plot** help in assessment of the goodness of fit for the nonparametric regression model. A well-fitted model typically show no pattern or structure in the residual plot, indicating that the error are randomly distributed around zero. Looking at the Residual plot vs fitted plots above, the majority of residual are randomly dispersed at around 0 suggesting that nonparametric regression model is acceptable and recommended for use.
```{r ,fig.align = 'center', echo=FALSE, fig.width = 8, fig.asp = .62}
plot_den<-densityPlot(~ res, show.bw=TRUE, method="kernel",xlab="Residual")
title(main="Residual Density Plot",font.main= 1)
abline(v = 0, col="red")
polygon(plot_den, col = rgb(0.78, 0.89, 1, alpha = 0.6))
```
**Residual Density Plot** is another method of evaluating models model fits, if the residuals follow a normal distribution, it is suggestion that the model is a good fit for the data. If the residuals deviate from a normal distribution, it is suggesting that the model may not be a good fit for our data and further analysis maybe needed. From our Residual Density Plot above, the distribution of our residual seems to form a bell-shape curve and centered at zero(indicated by the red line), suggesting that our residual is normally distributed and nonparametric regression model are a good fit for our data.

## 4. Conclusion

### 4.1 First set of models for predicting life expectancy

The two goals to evaluate and conclude during this project are a) to identify and arrive at a parsimonious model that can predict life expectancy to a level of $>80%$ with less variables than the orginal dataset b) to evaluate and show that a complex and mixed-type dataset is less likely to have all the predictor variables linearly related to the output response variable and thus likely will require a more flexible and complex model for better performance. On a side note, it is also an indicator that predicting life expectancy is complex. 

Both these goals have been successfully evaluated during the course of the project and the conclusion is that life expectancy is by nature not a normally distributed response variable. Performing simple linear regression modelling on this complex data is not sufficient or valid. There are two models that are identified that can be used to predict life expectancy with $R^2$ of more than 80% aka the two models are able to explain variation in life expectancy to an extent of $80%+$.

The nonparametric model has a higher $R^2$ of 87%(approx) when compared to the parametric model $R^2$ of 83%(approx). So, it is concluded that nonparametric model fits the given dataset better and is selected as the best one among all assessed models for use of predicting life expectancy.

In order to arrive at a more parsimonious model, significance of the variables used in nonparametric regression is measured and all the 12 variables are significant and recommended to be retained in the model. The variables selected in predicting life expectancy by the recommended models are: 'Adult.Mortality','infant.deaths','under.five.deaths','Hepatitis.B',
'BMI','Polio','Diphtheria','HIV.AIDS','thinness..1.19.years',
'Income.composition.of.resources','Schooling','GDP'.

### 4.2 Future improvements

Based on the knowledge of the domain and analysis from the data, different models and statistical tests are performed in the given time frame of this project to predict life expectancy. There are more opportunities for improvements we discovered during the course of this project and the team suggests the following for future exploration, studies and implementation to see if an even better-performing model can be attained.   

1. Currently, variables are used "as-is" from the dataset.  Some techniques for variable encoding/transformation and more flexible models like GAMs can be explored. 

2. Performing nonparametric model analysis consumed substantial amount of computing resources.  The results achieved so far is generally sufficient for measuring long run performance.  While resources and time allow in the future, consider fine-tuning this model by enforcing dataset splitting into training and testing sets, which can provide a better account on the predictive performance on unseen data.   

3. According to the earlier multicollinearity studies (Refer **Appendix**), correlation is found between the variables infant.deaths and under.five.deaths.  It is understood that such correlation may cause undesirable effect on model accuracy, fitting and interpretation.   To resolve this issue, it is suggested to remove one of the correlated variables with the higher VIF (Variable Inflation Factor) score.

4. Currently in the analysis, data is imputed for NA values (rather than removing the records with NA values) has been deployed to retain more information and the value generated by other valid data columns of the record.  Although data imputation is a common industry practice, different null data handling techniques (apart from data imputation using mean) can be investigated in future and compared with current results.


### 4.3 Interesting challenges

Every project deals with an interesting amount of challenges and there are some interesting challenges encountered during the course of this project as well. The team needed to pivot constantly in order to efficiently and confidently come up with the first suitable model for predicting life expectancy.    

1. Running npreg algorithm using R on this dataset is extremely time-consuming.  It took 30 hours in a notebook computer.  This undesirable situation has seriously constrained our flexibility in fine-tuning and re-running the model with different model settings such as different variables selection, train-test assessments because time is limited to compare different sets and select optimal fit.

2. Similarly, running model significance took more than 30 hours.  This has caused similar consequence as the previous point 1.

3. As mentioned in the earlier analysis, the distribution is not normal and this limited the application of several simple models that have a strong assumption on the underlying distribution.  The team also has very limited experience in bimodal or multimodal distributions so even though the response variable seems to be bimodal, no specific assessments or fitting is carried out. 


## 5. Appendix

### 5.1 Checking for Multicollinearity

As Multicollinearity can potentially affect the accuracy of regression model, a correlation study is undertaken to understand and assess the situation.  It is found that infant deaths and under.five.deaths are nearly 100% correlated. From the variable inflation factors (VIF) calculations as well, it is evident that the two variables have a high inflation factor of 166.764248 and 166.967503 respectively. Variable under.five.deaths need to be removed from the dataset and the models need to be assessed for their performance. LASSO model can handle multicollinearity automatically so there is no change in performance expected for the model.

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(car)
vif(model.step.bic)

#removed one of infant.deaths or under.five.deaths
```
