---
title: "Data 583 Life Expectancy (WHO)"
author: "Justin Chan, Kenny Tong, Viji Rajagopalan"
date: "22 Mar, 2023"
output:
  pdf_document: default
  html_document:
    df_print: paged
fontsize: 10pt
geometry: margin=2cm
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data 583 Life Expectancy - Final Report (Life Expectancy Data)

## 1. Introduction and Hypotheses
Life expectancy has always been an area of interest for humanity. The key to long live has remained an intriguing topic to people for decades.  The goal of this project is to study a dataset that contains information on life expectancy and identify some of the variables that significantly impact life expectancy. 

The dataset chosen for the study has life expectancy data of 193 countries between 2000-2015, together with different predictive factors. Broadly speaking, predicting variables are categorized into 4 major areas : Immunization, Mortality, Economical, and Social, containing a total of 21 individual  variables. Our hypothesis is that a subset of variables from this dataset would be able to explain and predict life expectancy with good accuracy (say > 80%). The dataset has a mix of variable types â€“ continuous and discrete. Within discrete types, some variables are ordinal, and some are non-ordinal or nominal. 

With such a mix and complexity of data, we also hypothesize that all variables will not share a simple linear relationship with the predictor variable and modelling of life expectancy will require a more complex model. We analyze and validate several statistical models throughout the report with the primary goal of identifying an adequate model for the dataset.


## 2. Dataset overview

### Variables Summary and Categories
Life expectancy is the response variable in this dataset.  This represents the mean life expectancy (in age) by specific country and year combination. Refer Table-1 and Table-2 below for the list of predictor variables and their categories.

The dataset contains 2563 missing values in various columns.  To handle the NA values in the dataset, two main procedures are taken.  Firstly, those countries with many NA values in different columns have their records removed from the dataset.  Consequently, 12 countries are removed from the dataset.  Secondly, the remaining records are imputed by the respective column mean.

To begin with, the 'Percentage expenditure' variable is removed from the entire assessment as the values present in this column are unclear. Another variable 'country' is also removed because we intend to focus on studying the life expectancy on a global basis. The resulting dataset are then studied more closely to understand their correlation effects with the response variable life expectancy.


|Variable     |Unit of Measurement/Data Category    | Continuous vs Discrete |   Variable     |Unit of Measurement/Data Category    | Continuous vs Discrete |
|-----        |-----                                | ----- |   -----        |-----                                | ----- |
|Life Expectancy |Years Old (Age)                   |Continuous  |Total expenditure|Percentage                       |Continuous|
|Country      |Nominal Data                         |Discrete  |Percentage expenditure|Percentage                  |Continuous|
|Year         |Ordinal Data                         |Discrete  |GDP          |Currency (USD)                       |Continuous|
|Status       |Nominal Data                         |Discrete  |Population   |Count                                |Discrete|
|Adult Mortality|Count Data                         |Discrete  |Income composition of resources|Percentage         |Continuous|
|Infant deaths|Count Data                           |Discrete  |Schooling    |Mean (Years)                         |Continuous|
|Under-five deaths|Count Data                       |Discrete  |Alcohol      |Litres                               |Continuous|
|Hepatitis B  |Percentage                           |Continuous  |HIV/AIDS     |Percentage                           |Continuous|
|Measles      |Count Data                           |Discrete  |BMI          |Average BMI                          |Continuous|
|Polio        |Percentage                           |Continuous  |Thinness 1-19 years|Percentage                     |Continuous|
|Diphtheria   |Percentage                           |Continuous  |Thinness 5-9 years|Percentage                      |Continuous|

\begin{center}
Table 1 : List of Predictor Variables
\end{center}

Following table shows how the above variables are grouped based on the 4 categories.

|  **Data Categories**   |    **Variables**                                                                              |
|------------------------|----------------------------------------------------------------------------------------------|
| **Economical Data**    | Total expenditure, Percentage expenditure, GDP, Income composition of resources              |
| **Social Data**        | Country, Status, Population, Schooling, Alcohol, BMI, Thinness 1-19 years, Thinness 5-9 years|
| **Mortality Data**     | Adult Mortality, Infant deaths, Under-five deaths                                            |
| **Immunization Data**  | Hepatitis B, Measles, Polio, HIV/AIDS, BMI, Diphtheria                                       |

\begin{center}
Table 2 : Variable Categories
\end{center}

```{r, include=FALSE}
### Start of EDA section - retained in Rmd

le <- read.csv("dataset/LifeExpectancy.csv")

# Create a new column Status.val to represent the Status column with number
le$Status.val <- ifelse(le$Status == "Developed",1,0)
# Create a new column as the scaled version of the GDP & Population, 
#le$GDP_scaled = scale(le$GDP)
#le$Population_scaled = scale(le$Population)
# Remove the unreliable column 
le <- subset(le,select=-c(percentage.expenditure))
```

```{r, include=FALSE}
# Null Data Handling
library(magrittr) 
library(dplyr)  
library(tidyr)
le %>% group_by(Country) %>% summarise(COUNT = n())
```


```{r message=FALSE, warning=FALSE, include=FALSE}
# Null Data Analysis
library(magrittr) 
library(dplyr)  
library(tidyr)
missing.values <- le %>%
    gather(key = "key", value = "val") %>%
    mutate(is.missing = is.na(val)) %>%
    group_by(key, is.missing) %>%
    summarise(num.missing = n()) %>%
    filter(is.missing==T) %>%
    select(-is.missing) %>%
    arrange(desc(num.missing))

```


```{r message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
library(gridExtra)
missing.values <- le %>%
  gather(key="key", value="val") %>%
  mutate(isna=is.na(val)) %>%
  group_by(key) %>%
  mutate(total=n()) %>%
  group_by(key,total,isna) %>%
  summarise(num.isna=n()) %>%
  mutate(pct=num.isna/total * 100)
levels <- (missing.values%>%filter(isna==T) %>% arrange(desc(pct)))$key
null_percentage.plot <- missing.values %>% ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), stat='identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('dodgerblue2', 'coral'), 
                        labels = c("Present", "Missing")) +
      coord_flip() + labs(title = "Percentage of missing values", 
                          x = 'Features', y = "% of missing values")
null_inrow.plot <- le %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('dodgerblue2', 'coral'),
        labels = c("Present", "Missing")) +
    scale_x_discrete(limits = levels) +
    labs(x = "Features", y = "Row Number", title = "Missing values in rows") +
    coord_flip()
library(dplyr)
#le_dropped <- le %>% filter_at(vars(Population_scaled,Population,GDP,GDP_scaled,Income.composition.of.resources,Schooling),any_vars(!is.na(.)))
le_dropped <- le %>% filter_at(vars(Population,GDP,Income.composition.of.resources,Schooling),any_vars(!is.na(.)))
missing.values <- le_dropped %>%
  gather(key="key", value="val") %>%
  mutate(isna=is.na(val)) %>%
  group_by(key) %>%
  mutate(total=n()) %>%
  group_by(key,total,isna) %>%
  summarise(num.isna=n()) %>%
  mutate(pct=num.isna/total * 100)
#missing.values
levels <- (missing.values%>%filter(isna==T) %>% arrange(desc(pct)))$key
null_percentage_dropped.plot <- missing.values %>% ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), stat='identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('dodgerblue2', 'coral'), 
                        labels = c("Present", "Missing")) +
      coord_flip() + labs(title = "Percentage of missing values after dropping some common null value records", 
                          x = 'Features', y = "% of missing values")
null_inrow_dropped.plot <- le_dropped %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('dodgerblue2', 'coral'),
        labels = c("Present", "Missing")) +
    scale_x_discrete(limits = levels) +
    labs(x = "Features", y = "Row Number", title = "Missing values in rows after dropping some common null value records") +
    coord_flip()

#options(repr.plot.width = 30, repr.plot.height = 30)
#gridExtra::grid.arrange(null_percentage.plot, null_inrow.plot, ncol = 1)
#gridExtra::grid.arrange(null_percentage_dropped.plot, null_inrow_dropped.plot, ncol = 1)

```


<!-- Check how much records do each country have:  -->
```{r message=FALSE, warning=FALSE, include=FALSE}
le %>% group_by(Country) %>% summarise(COUNT = n())
le_dropped %>% group_by(Country) %>% summarise(COUNT = n()) #12 country were removed after dropping some common null value (193-181)
#might need to consider not using this variable 
```


```{r message=FALSE, warning=FALSE, include=FALSE}
for(i in 1:ncol(le_dropped)) {                                   # Replace NA in all columns
  le_dropped[ , i][is.na(le_dropped[ , i])] <- mean(le_dropped[ , i], na.rm = TRUE)
}
```


```{r, eval=FALSE, fig.height=2, fig.width=2, message=FALSE, warning=FALSE, include=FALSE}
library(ggplot2)
#install.packages("tidyverse")
library(tidyverse)
par(mfrow=c(1,2))
le_dropped %>%
  group_by(Year) %>%
  summarise(Life.expectancy = mean(Life.expectancy)) %>%
  ggplot(aes(x=Year,
             y=Life.expectancy)) +    
  geom_line()

le_dropped %>%
  group_by(Status) %>%
  summarise(Life.expectancy = mean(Life.expectancy)) %>%
  ggplot(aes(x=Status,
             y=Life.expectancy,
             fill=Status)) +    
  geom_bar(stat = "identity")+ scale_fill_manual(values=c('dodgerblue2', 'coral'))

```


```{r, eval=FALSE, fig.height=2, message=FALSE, warning=FALSE, include=FALSE}
le_dropped.pivot <- pivot_longer(le_dropped,c(Adult.Mortality,under.five.deaths,infant.deaths),names_to='Mortality.Group',values_to='Mortality.Rate')
require(gridExtra)

le_dropped.pivot.area <- le_dropped.pivot %>%
  group_by(Year,Mortality.Group) %>%
  summarise(Mortality.Rate = mean(Mortality.Rate)) %>%
  ggplot(aes(x=Year,
             y=Mortality.Rate,
             fill=Mortality.Group)) +
  geom_area(position="stack",stat="identity")

le_dropped.pivot.line <- le_dropped.pivot %>%
  group_by(Year,Mortality.Group) %>%
  summarise(Mortality.Rate = mean(Mortality.Rate)) %>%
  ggplot(aes(x=Year,
             y=Mortality.Rate,
             color=Mortality.Group)) +
  geom_line()

grid.arrange(le_dropped.pivot.area,le_dropped.pivot.line, ncol=2)
```


```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
head(le_dropped)
```

```{r warning=FALSE, include=FALSE}

#df = subset(le_dropped, select = -c(Country,GDP,Population) )
df = subset(le_dropped, select = -c(Country,Status.val) )
head(df)

```

The resulting dataset are then studied closely to understand their correlation effects with the response variable life expectancy. Following is a correlation matrix on all the variables in the dataset.

```{r message=FALSE, warning=FALSE, echo=FALSE}

#install.packages(GGally)
library(GGally)
ggcorr(df,palette = "RdBu", size=2,label=TRUE,label_size = 2,hjust = .95,layout.exp=2)+labs(title = "Correlation Matrix Plot")+ theme(plot.title = element_text(size=20))

```

\begin{center}
Plot 1 : GG Variables Correlation Plot
\end{center}

It can be noted that the response variable life expectancy is highly correlated with income composition, schooling and adult mortality variables with a correlation value of $0.7$, $0.7$ and $-0.7$. Life expectancy is moderately correlated with variables BMI, Polio, Diphtheria, HIV.AIDS and thinness variables with a correlation value of $0.6$, $0.5$, $0.5$, $-0.6$, $-0.5$. Broadly, it can be noted that the two categories of the variables appear to be highly correlated with life expectancy when compared to other categories.

### Initial analysis using linear regression
Life expectancy is a continuous variable and the first choice is building a linear regression model which is simple and interpretable. A BIC backward step model variable selection method is also applied on the full model to arrive at a parsimonious model containing only significant predictor variables. Following table Table A provides a summary of the two models.



|Models           |No. of Variables |AIC Score    |Adj R-squared Score|
|-----            |-----            |-----        |-----|       
|Original Model   |20               |7642.14      |0.8299|
|Reduced Model    |12               |7604.24      |0.8296|

\begin{center}
Table 3 :Original vs Reduced Models
\end{center}

Note that we have also eliminated the Status variable in the reduced model as this is a factor variable with two statuses and not continuous. We plan to first study the effect of the model without this variable.  Finally, the number of independent variables is now effectively reduced to 12, achieving a lower AIC score of 7604.34. Meanwhile, the adjusted R-squared score is well kept at nearly the same level as in the original model.  The reduced model is able to explain more than 82% of variation in the response variable and its performance is above the anticipated 80%. 

Specifically, the reduced model now contains the following 12 variables : Adult.Mortality + infant.deaths + Hepatitis.B + BMI + under.five.deaths + Polio + Diphtheria + HIV.AIDS + GDP + thinness..1.19.years + Income.composition.of.resources + Schooling.

To conclude, the reduced model from this step is selected as the first model for the dataset.  The dataset now has `r nrow(df)` records and 12 columns. It is used for further evaluation from a linear model stand point and will be referred to as linear model in the remainder of the discussion. 

```{r message=FALSE, warning=FALSE, include=FALSE}
#### Full model summary and diagnostics
lmmod <- lm(Life.expectancy~., data = df)
summary(lmmod)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
model.step.bic <- step(lmmod,k=log(nrow(df)))
summary(model.step.bic)
```



```{r message=FALSE, warning=FALSE, include=FALSE}
df1<-df[,c('Life.expectancy','Adult.Mortality','infant.deaths','under.five.deaths',
      'Hepatitis.B','BMI','Polio','Diphtheria',
      'HIV.AIDS','thinness..1.19.years','Income.composition.of.resources','Schooling','GDP')]

# df1$Status <- factor(df1$Status)
# removed 'under.five.deaths', due to vif - multi collinearity from BIC selection but it decreased model
#  performance so should we retain it?
#head(df1)
```



```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#not carrying forward any clustering analysis for the first release of the report due to time
#constraints
library(mclust)
clus1 <- Mclust(df1)
summary(clus1)
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
library(car)
lmmod2 <- lm(Life.expectancy~.,data=df1)
summary(lmmod2)
vif(lmmod2)

### End of EDA
### Start of model building and assessments
```


## 3. Regression Analysis


### Linear model and diagnostics

The linear model shows that we are able to explain approximately 82% of variability of our response variable using the selected predictor variables. The next step is to look at the error diagnostics from the model.

```{r,echo=TRUE,results='markup',fig.align = 'center'}
par(mfrow=c(2,2))

plot(lmmod2)
mtext("Diagnostic Plots for Linear Regression Analysis", side = 3, line = -1, outer = TRUE)

```

The QQ plot suggests that the model is heavy tailed and the data on both ends of the quantiles do not fit on a straight line. This is an indication that the current linear regression based model is not fitting the data well. Based on this, we undertake additional testing to validate if the model is adequate and valid.


#### a. Life expectancy variable distribution


```{r,echo=TRUE,results='markup',fig.align = 'center' }
densityPlot(~ Life.expectancy, show.bw=TRUE, method="kernel", data = df, xlab="age")
title(main="Density Plot",font.main= 1)
```
From the Density plot above, it can be seen that the mean of the distribution isn't symmetrical and the mean isn't centered at 0, indicating the response variable life expectancy is not normally distributed. From the Normal QQ plot of the regression model, it can be observed that there is a distinct curve in the middle of plot rather than a straight line, this indicates that there could be a bimodal distribution to response variable. These observations necessitate validation of distribution of the response variable. One of the assumptions of linear model is that the response variable is normally distributed and if it is proven that the variable is not normally distributed, linear regression model for this dataset will be  invalid due to violation of assumptions.


#### b. Normal distribution test for response variable 

Shapiro-Wilk test is a statistical test for normality and a p-value that is very small and is less than 0.05 proves the variable in consideration is not normally distributed. Shapiro-Wilk test on the response variable life expectancy resulted in a p-value of < 2.2e-16 as seen in the test output below.

```{r echo = FALSE}
#Shapiro-Wilk Test

shapiro.test(df$Life.expectancy)

#Finding: Since df$Life.expectancy p-value is less than .05, indicate that our y variable is not normally distributed!!!
```
This proves the response variable is not normally distributed and additionally, hypothesis tests for validating correct specification of parametric MLR models are conducted to identify if the selected linear model specification is valid for the given dataset.


#### c. Parametric model specification test

Ramsey's RESET test is a test conducted to validate the correctness of the functional form. A p-value that is very small and is less than 0.05 rejects that the functional form is correctly specified. RESET test is conducted on the linear model and the resulting p-value as seen from the output below is $< 2.2e-16$.

```{r}
library(lmtest)
resettest(lmmod2)
```
Based on the test, the linear model is rejected as the correct functional form for modelling the underlying data.

#### d. Consistent nonparametric inference

The consistent nonparametric inference test is a hypothesis test for correct specification of parametric MLR models. This allows to estimate if the functional for given parameter estimates is reasonable when compared. A p-value that is very small and is less than 0.05 rejects that the functional form for given parameter estimates is reasonable.

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
#LM with matching dependent variable with npreg
model_lm <- lm(Life.expectancy~Adult.Mortality + infant.deaths + Hepatitis.B + BMI + under.five.deaths + Polio + Diphtheria + HIV.AIDS + GDP + thinness..1.19.years + Income.composition.of.resources + Schooling, data = df, x=TRUE, y=TRUE)
summary(model_lm)
```

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
# X <- data.frame(df$Adult.Mortality,df$infant.deaths,df$Hepatitis.B,df$BMI,df$under.five.deaths,df$Polio,df$Diphtheria,df$HIV.AIDS,df$GDP,df$thinness..1.19.years,df$Income.composition.of.resources,df$Schooling)
# 
# result_npcms <- npcmstest(model=model_lm, xdat=X, ydat=df$Life.expectancy) #33Hours to run
```

```{r echo=FALSE}
# result_npcms

# objects()
# find("result_npcms")
# 
# saveRDS(result_npcms,"result_npcms.rds")
result_npcms <- readRDS("result_npcms.rds") #PreTrained Model
summary(result_npcms)
```

As noted from above table, the p-value for linear model is $< 2.22e-16$ and this output suggests that the linear model is rejected.

All the diagnostic tests indicate that linear regression is not an appropriate model for the given data. This proves one of the hypothesis of our project that a simple linear model may not be adequate in explaining the variability in the response variable life expectancy.


### Parametric regression models and relative assessments

As the linear model is not adequate, we move on to other parametric regression models that do not assume normal distribution and known to perform well on complex and mixed data types. There are several models that could be used in the assessments and we selected LASSO and Neural Net with  linear activation function for the given dataset. 

The following variables are selected for rest of the modeling based on correlation of the variables with the response variable and our knowledge on the domain. Here is a summary of the variable selection and  comments describing the reason for removal of the variable.


| **Column Name **       | **Type **         | **LM ** | **LASSO **   | **NN ** | **NPREG **    | **Reason of Removal**                                                       |
|------------------------|-------------------|---------|--------------|--------|--------------|-----------------------------------------------------------------------------|
| Country                          | (Discrete)   |        |           |        |           | Since we wanted to build models for all countries                           |
| Year                             | (Discrete)   |        |           |        |           | ordinal type data and based on domain knowledge, not consider important     |
| Status                           | (Discrete)   |        |           |        |           | nominal type data and based on domain knowledge, not consider important     |
| Adult Mortality                  | (Discrete)   | X      | X         |X       | X         |                                                                             |
| Infant deaths                    | (Discrete)   | X      | X         |X       | X         |                                                                             |
| Under-five deaths                | (Discrete)   | X      | X         |X       | X         |                                                                             |
| Hepatitis B                      | (Continuous) | X      | X         |X       | X         |                                                                             |
| Measles                          | (Discrete)   |        |           |        |           | Since it is a count and discrete type data and weak correlation with our predictor                  |
| Polio                            | (Continuous) | X      | X         |X       | X         |                                                                             |
| Diphtheria                       | (Continuous) | X      | X         |X       | X         |                                                                             |
| Total Expenditure                | (Continuous) |        |           |        |           | based on domain knowledge, not consider important                           |
| Percentage Expenditure           | (Continuous) |        |           |        |           | based on domain knowledge, not consider important                           |
| GDP                              | (Continuous) | X      | X         |X       | X         |                                                                             |
| Population                       | (Discrete)   |        |           |        |           | no correlation with our predictor indicated by our correlation plot         |
| Income composition of resources  | (Continuous) | X      | X         |X       | X         |                                                                             |
| Schooling                        | (Continuous) | X      | X         |X       | X         |                                                                             |
| Alchol                           | (Continuous) |        |           |        |           | based on domain knowledge, not consider important                           |
| HIV/AIDS                         | (Continuous) | X      | X         |X       | X         |                                                                             |
| BMI                              | (Continuous) | X      | X         |X       | X         |                                                                             |
| Thinness 1-19 years              | (Continuous) | X      | X         |X       | X         |                                                                             |
| Thinness 5-9 years               | (Continuous) |        |           |        |           | range already covered in 1-19 Thinness 1-19 years                           |
| status.val                       | (Continuous) |        |           |        |           | based on domain knowledge, not consider important                           |


First, the dataset is divided into a train and test datasets with an approximate 70%-30% of the complete data using a random sampling process so long run performance of the models can be estimated. The train dataset has 2000 records and test dataset has 778 records in total.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(glmnet)
# approximately 70:30 split for train and test

df1<-df[,c('Life.expectancy','Adult.Mortality','infant.deaths','under.five.deaths',
      'Hepatitis.B','BMI','Polio','Diphtheria',
      'HIV.AIDS','thinness..1.19.years','Income.composition.of.resources','Schooling','GDP')]

ind <- sample(1:nrow(df1), 2000)
traino <- df1[ind,]
testo <- df1[-ind,]
```



```{r message=FALSE, warning=FALSE, include=FALSE}
#linear model for comparison
lmmodtr <- lm(traino[,1]~.,data=traino[,-1],x=TRUE, y=TRUE)
summary(lmmodtr)

```

```{r message=FALSE, warning=FALSE, include=FALSE}
#LASSO
library(glmnet)
y <- traino$Life.expectancy
x <- data.matrix(traino[,-1])
#k-fold cross-validation to find optimal lambda value\
#cv default is 10 fold
cv_model <- cv.glmnet(x, y, alpha = 1)

#optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda
plot(cv_model) 

#coefficients of best model
lasmod <- glmnet(as.matrix(traino[,-1]),traino$Life.expectancy, alpha = 1, lambda = best_lambda)
coef(lasmod)
```


```{r message=FALSE, warning=FALSE, include=FALSE}
#linear model
mselm_te1 <- mean((testo[,1]-predict(lmmodtr, newdata=testo))^2)

#lasso
mselas_te1 <- mean((testo[,1]-predict(lasmod, newx=as.matrix(testo[,-1])))^2)

```

```{r message=FALSE, warning=FALSE, include=FALSE}
library(nnet)
#18 MSE
hidden <- 0
nnmse <- 0
for(i in 1:62){
  
  set.seed(4521)
  
  train_lin <- nnet(traino[,1]~., data=traino, size=i, linout=TRUE, trace=FALSE)
#calculating mse

  mse_nnet_lin <- mean((testo[,1]-(predict(train_lin, newdata=testo)))^2)
  hidden[i] <- i
  nnmse[i] <- mse_nnet_lin
  #print(paste("Number of hidden layer variables:", i))
  #print(paste("MSE:",mse_nnet_lin))
  
}
```

Three types of models using linear regression (LM), LASSO and NeuralNet with linear activation function are built on the $train$ dataset and the PRESS (Predicted Residual Error Sum of Squares) statistic is calculated using $test$ to identify the best performing model. Following table summarizes and compares the PRESS statistics.

|           | **LM**   | **LASSO** | **NN**   |
|-----------|----------|-----------|----------|
| **PRESS** | 15.93367 | 15.98972  | 22.43056 |

Based on the output, it can be seen that LM and LASSO models perform better than NeuralNet model for this dataset. P.S: Linear model is used in these assessments for benchmarking purposes and not for actual use as the model is not valid.

```{r include=FALSE}
# #MSE comparison
# print(mselm_te1)
# print(mselas_te1)
# print(min(mse_nnet_lin))

```

Selecting LM and LASSO, the $R^2$ is also measured for the models. It can be seen that LASSO performs nearly at the same level as the linear model (LM).

|        | **LM**            | **LASSO**         |
|--------|-------------------|-------------------|
| **R2** | 0.829139273435324 | 0.829061931452822 |

```{r include=FALSE}
# #Linear Model R2
# r2_lm<- summary(lmmodtr)$r.squared
# paste("Linear Model R2: ",r2_lm)
# 
# #Lasso R2
# r2_lasso <- lasmod$dev.ratio
# paste("Lasso R2: ",r2_lasso)

```


Based on these assessments, LASSO is a viable model that can be considered for this dataset that has approximately $82%$ for predicted R^2 value and meets the performance goals expectations.

#### Diagnostics

### Nonparametric regression

Nonparametric regression is considered as another good option for the complex and mixed dataset that is of interest here due to proven flexibility and adaptability nature of these models. One important difference between nonparametric model and rest of the parametric models is that the entire data is used in the model training process. The nonparametric regression is carried out with local linear estimator and cv.aic for automated bandwidth selection. This bandwidth selection method specifies expected Kullback-Leibler cross-validation (Hurvich, Simonoff, and Tsai (1998))and in general provides consistent estimates. 

```{r cache=TRUE, include=FALSE}
library(np)
# n <- names(df)
# f <- as.formula(paste("df$Life.expectancy ~", paste(n[!n %in% "Life.expectancy"], collapse = " + ")))
# 
# model_np <- npregbw(Life.expectancy ~ Adult.Mortality + infant.deaths + Hepatitis.B + BMI + under.five.deaths + Polio + Diphtheria + HIV.AIDS + GDP + thinness..1.19.years + Income.composition.of.resources + Schooling, data = df, regtype="ll", bwmethod = "cv.aic")    #19 HRs to run...

# model_np <- npreg(bws = model_np)
# summary(model_np)
model_np <- readRDS("model_np.rds") #PreTrained Model
summary(model_np)
```
The output of the nonparametric regression model indicates an $R^2$ value of 87% approximately. This is the summary measure of in-sample fit for the model lies in the range of [0,1]. 1 denotes a perfect fit to the sample data and 0 indicates no fit. This is the counterpart to $R^2$ of linear model.

We acknowledget that the $R^2$ for LASSO model is calculated based on a train vs test setup and nonparametric regression $R^2$ is calculated on the complete dataset and a nonparamertic train-test fitting is identified as a future scope item that will be looked into. As the nonparametric model is a cross validated model and can provide long run performance, the LASSO and nonparametric model coeffients are compared and summarized in the table below.

|        | **NPREG**            | **LASSO**         |
|--------|-------------------|-------------------|
| **R2** | 0.8722143         | 0.829061931452822 |

The nonparametric model has a higher $R^2$ of 87%(approx) when compared to the parametric model $R^2$ of 83%(approx). So, it is concluded that nonparametric model fits the given dataset better and is selected among the assessed models for use.

In order to arrive at a more parsimonious model, significance of the variables used in nonparametric regression is measured and per below output all the variables are significant and will be retained in the model. 

```{r cache=TRUE}
#npsigtest_npreg <- npsigtest(model_np)    #10 HRs to run...
```
![npsigtest_npreg result](dataset/npsigtest_npreg.png)

#### Diagnostics


## 4. Conclusion
The non-normality nature of the dataset has been observed and verified by rigorous testings and validation in this report.  This characteristic has greatly limited the applicablity of many popular common models which rely on the assumption of normal distribution.  After further model assessment, we are finally able to come into the best available conclusion that NOREG and LASSO are the two best-performing models based on model performance indicators like MSE and R-squared values.  

We find that life expectancy is....[KT : I literally have no idea what to put there....may be I leave it to Viji to continue and finally conclude the report :) ]

### Future improvements
While a number of different models and statistical tests have been explored within a limited time frame of this project, we can hardly conclude we have identified the globally optimal models.  In fact, in order to limit the complication of this analysis and make it reasonably achievable, we have adopted certain model and analysis simplification in a few aspects.  These assumptions/simplification may, however, potentially have adverse effect on our underlying models accuracy.  As rooms of further improvement works based on this report, the following aspects are suggested for future exploration, studies and implementation to see if an even better-performing model can be attained.   

1. Currently, no particular handling has been done to process the categorical, ordinal, and nominal variables.  Current variables are simply fit into different models with "as-is" data basis.  Further exploration on whether some techniques (such as Variables Encoding/transformation, factorization factor()) can be deployed to achieve models improvement is preferable.

2. Performing non-parametric model in our analysis has taken a substantial amount of computing resources.  The studies on the non-parametric model what we have achieved so far is generally sufficient for measuring long run performance.  While resources and time allow in the future, we may consider performing further fine-tuning on this by enforcing dataset splitting into training and testing set under non-parametric model fitting, which can possibly have a better account of the model performance.   

3. According to the earlier Multicollinearity studies (Part 2), correlation is found between the variables infant.deaths and under.five.deaths.  It is understood that such correlation may cause undesirable effect on model accuracy, fitting and interpretation.   To resolve this issue, we may explore possible tactics such as removing one of the correlated variables, or using factor analysis (factanal) to address the multicollinearity issue to enhance the models.

4. Currently in our analysis, data implantation (rather than removing the records with NA values) has been deployed in order to retain as many records as possible and simplify/streamline the subsequent analysis.  Although data implantation is a common industry practice, We are not 100% sure if such procedure would affect the model accuracy.  In this regard, we may investigate and compare different null data handling techniques (apart from data implantation using mean) and investigate if we can achieve our modelling improvement as a result.


### Interesting challenges
During this project, a number of challenges are encountered.  These challenges have created extra hurdles and unforeseeable overheads on our projects, or have caused unexpected complication for the project team in order to efficiently and confidently identify the most suitable models.    

1. Running npreg on our model is extremely time-consuming.  It took 30 hours in a notebook computer.  This undesirable situation has seriously constrained our flexibility in fine-tuning and re-running the model with different model settings such as variable combination because we simply cannot afford adjusting the model fitting to look more a potentially more optimal model fitting.

2. Similarly, running model significance took more than 30 hours.  This has caused similar consequence as the previous point 1.

3. As mentioned in the earlier analysis, bimodal distribution is identified in the dataset, which has violated the basic assumptions of many parametric models.  This behavior has therefore severely limited the applicability of many parametric modelling.  We also lack of sufficient knowledge on how to optimally model and analyze bimodal distribution.

4. The dataset has demonstrated quite a high proportion of NA values.  Several columns contain significantly more than 5% of NA values.  If we decide to adopt the 5% threshold and remove all records (e.g. dropping columns or removing rows) with NA values which exceeds the 5% threshold, it would result in a significant amount of records being removed and only remain a much smaller sample size available for further analysis.  This may tremendously and adversely impact and deteriorate the analysis accuracy and reliability. 


## Appendix
### Checking for Multicollinearity
As Multicollinearity can potentially affect the accuracy of regression model and we have 22 variables, a correlation study is undertaken to understand and assess the situation.  A correlation plot has identified a number of correlation problems.  It is found that infant deaths and under.five.deaths are nearly 100% correlated.  The relation between the deaths rates of the two close age groups is easily interpretable.  In addition, there are three heavily correlated pairs which is defined by the abs(correlation coefficient)>0.7 between the variables.  They include (a) (immunization rate of) â€˜Polioâ€™-vs-â€˜Diphtheriaâ€™,  (b) â€˜income composition of resourcesâ€™-vs-â€˜Schoolingâ€™, and (c) between the two thinness measures for the age groups 5-9 vs 10-19.   Pairs (a) and (c) are justifiable while the relation for (b) demonstrate a relatively subtle relation.  Other than that, the degree of multicollinearity is acceptable and not too worrying.

```{r, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}
library(car)
vif(model.step.bic)

#removed one of infant.deaths or under.five.deaths
```
